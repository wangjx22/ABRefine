+ POD_NAME=nb-refinement-0-px5ws-worker-0
+ shift
+ /opt/kube/kubectl exec nb-refinement-0-px5ws-worker-0 -- /bin/sh -c        PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess "env" -mca ess_base_jobid "3468165120" -mca ess_base_vpid 1 -mca ess_base_num_procs "2" -mca orte_node_regex "nb-refinement-[1:0]-px5ws-launcher,nb-refinement-[1:0]-px5ws-worker-0@0(2)" -mca orte_hnp_uri "3468165120.0;tcp://172.22.72.89:52014" -mca pml "ob1" -mca btl "^openib" -mca plm "rsh" --tree-spawn -mca routed "radix" -mca orte_parent_uri "3468165120.0;tcp://172.22.72.89:52014" -mca orte_default_hostfile "/etc/mpi/hostfile" -mca plm_rsh_agent "/etc/mpi/kubexec.sh" -mca orte_tag_output "1" -mca hwloc_base_binding_policy "none" -mca rmaps_base_mapping_policy "slot" -mca pmix "^s1,s2,cray,isolated"
[1,0]<stderr>:+ source activate /nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:++ _CONDA_ROOT=/opt/conda
[1,0]<stderr>:++ . /opt/conda/etc/profile.d/conda.sh
[1,0]<stderr>:+++ export CONDA_EXE=/opt/conda/bin/conda
[1,0]<stderr>:+++ CONDA_EXE=/opt/conda/bin/conda
[1,0]<stderr>:+++ export _CE_M=
[1,0]<stderr>:+++ _CE_M=
[1,0]<stderr>:+++ export _CE_CONDA=
[1,0]<stderr>:+++ _CE_CONDA=
[1,0]<stderr>:+++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
[1,0]<stderr>:+++ CONDA_PYTHON_EXE=/opt/conda/bin/python
[1,0]<stderr>:+++ '[' -z '' ']'
[1,0]<stderr>:+++ export CONDA_SHLVL=0
[1,0]<stderr>:+++ CONDA_SHLVL=0
[1,0]<stderr>:+++ '[' -n '' ']'
[1,0]<stderr>:+++++ dirname /opt/conda/bin/conda
[1,0]<stderr>:++++ dirname /opt/conda/bin
[1,0]<stderr>:+++ PATH=/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+++ export PATH
[1,0]<stderr>:+++ '[' -z '' ']'
[1,0]<stderr>:+++ PS1=
[1,0]<stderr>:++ conda activate /nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:++ local cmd=activate
[1,0]<stderr>:++ case "$cmd" in
[1,0]<stderr>:++ __conda_activate activate /nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:++ '[' -n '' ']'
[1,0]<stderr>:++ local ask_conda
[1,0]<stderr>:+++ PS1=
[1,0]<stderr>:+++ __conda_exe shell.posix activate /nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:+++ __add_sys_prefix_to_path
[1,0]<stderr>:+++ '[' -n '' ']'
[1,0]<stderr>:++++ dirname /opt/conda/bin/conda
[1,0]<stderr>:+++ SYSP=/opt/conda/bin
[1,0]<stderr>:++++ dirname /opt/conda/bin
[1,0]<stderr>:+++ SYSP=/opt/conda
[1,0]<stderr>:+++ '[' -n '' ']'
[1,0]<stderr>:+++ PATH=/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+++ export PATH
[1,0]<stderr>:+++ /opt/conda/bin/conda shell.posix activate /nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:++ ask_conda='PS1='\''(/nfs_beijing/kubeflow-user/jinxian_2024) '\''
[1,0]<stderr>:export PATH='\''/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
[1,0]<stderr>:export CONDA_PREFIX='\''/nfs_beijing/kubeflow-user/jinxian_2024'\''
[1,0]<stderr>:export CONDA_SHLVL='\''1'\''
[1,0]<stderr>:export CONDA_DEFAULT_ENV='\''/nfs_beijing/kubeflow-user/jinxian_2024'\''
[1,0]<stderr>:export CONDA_PROMPT_MODIFIER='\''(/nfs_beijing/kubeflow-user/jinxian_2024) '\''
[1,0]<stderr>:export CONDA_EXE='\''/opt/conda/bin/conda'\''
[1,0]<stderr>:export _CE_M='\'''\''
[1,0]<stderr>:export _CE_CONDA='\'''\''
[1,0]<stderr>:export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\''
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libblas_mkl_activate.sh"
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libglib_activate.sh"
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/proj4-activate.sh"'
[1,0]<stderr>:++ eval 'PS1='\''(/nfs_beijing/kubeflow-user/jinxian_2024) '\''
[1,0]<stderr>:export PATH='\''/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\''
[1,0]<stderr>:export CONDA_PREFIX='\''/nfs_beijing/kubeflow-user/jinxian_2024'\''
[1,0]<stderr>:export CONDA_SHLVL='\''1'\''
[1,0]<stderr>:export CONDA_DEFAULT_ENV='\''/nfs_beijing/kubeflow-user/jinxian_2024'\''
[1,0]<stderr>:export CONDA_PROMPT_MODIFIER='\''(/nfs_beijing/kubeflow-user/jinxian_2024) '\''
[1,0]<stderr>:export CONDA_EXE='\''/opt/conda/bin/conda'\''
[1,0]<stderr>:export _CE_M='\'''\''
[1,0]<stderr>:export _CE_CONDA='\'''\''
[1,0]<stderr>:export CONDA_PYTHON_EXE='\''/opt/conda/bin/python'\''
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libblas_mkl_activate.sh"
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libglib_activate.sh"
[1,0]<stderr>:. "/nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/proj4-activate.sh"'
[1,0]<stderr>:+++ PS1='(/nfs_beijing/kubeflow-user/jinxian_2024) '
[1,0]<stderr>:+++ export PATH=/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+++ PATH=/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+++ export CONDA_PREFIX=/nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:+++ CONDA_PREFIX=/nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:+++ export CONDA_SHLVL=1
[1,0]<stderr>:+++ CONDA_SHLVL=1
[1,0]<stderr>:+++ export CONDA_DEFAULT_ENV=/nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:+++ CONDA_DEFAULT_ENV=/nfs_beijing/kubeflow-user/jinxian_2024
[1,0]<stderr>:+++ export 'CONDA_PROMPT_MODIFIER=(/nfs_beijing/kubeflow-user/jinxian_2024) '
[1,0]<stderr>:+++ CONDA_PROMPT_MODIFIER='(/nfs_beijing/kubeflow-user/jinxian_2024) '
[1,0]<stderr>:+++ export CONDA_EXE=/opt/conda/bin/conda
[1,0]<stderr>:+++ CONDA_EXE=/opt/conda/bin/conda
[1,0]<stderr>:+++ export _CE_M=
[1,0]<stderr>:+++ _CE_M=
[1,0]<stderr>:+++ export _CE_CONDA=
[1,0]<stderr>:+++ _CE_CONDA=
[1,0]<stderr>:+++ export CONDA_PYTHON_EXE=/opt/conda/bin/python
[1,0]<stderr>:+++ CONDA_PYTHON_EXE=/opt/conda/bin/python
[1,0]<stderr>:+++ . /nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libblas_mkl_activate.sh
[1,0]<stderr>:++++ export CONDA_MKL_INTERFACE_LAYER_BACKUP=
[1,0]<stderr>:++++ CONDA_MKL_INTERFACE_LAYER_BACKUP=
[1,0]<stderr>:++++ export MKL_INTERFACE_LAYER=LP64,GNU
[1,0]<stderr>:++++ MKL_INTERFACE_LAYER=LP64,GNU
[1,0]<stderr>:+++ . /nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/libglib_activate.sh
[1,0]<stderr>:++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
[1,0]<stderr>:++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
[1,0]<stderr>:++++ export GSETTINGS_SCHEMA_DIR=/nfs_beijing/kubeflow-user/jinxian_2024/share/glib-2.0/schemas
[1,0]<stderr>:++++ GSETTINGS_SCHEMA_DIR=/nfs_beijing/kubeflow-user/jinxian_2024/share/glib-2.0/schemas
[1,0]<stderr>:+++ . /nfs_beijing/kubeflow-user/jinxian_2024/etc/conda/activate.d/proj4-activate.sh
[1,0]<stderr>:++++ '[' -n '' ']'
[1,0]<stderr>:++++ '[' -d /nfs_beijing/kubeflow-user/jinxian_2024/share/proj ']'
[1,0]<stderr>:++++ export PROJ_LIB=/nfs_beijing/kubeflow-user/jinxian_2024/share/proj
[1,0]<stderr>:++++ PROJ_LIB=/nfs_beijing/kubeflow-user/jinxian_2024/share/proj
[1,0]<stderr>:++++ '[' -f /nfs_beijing/kubeflow-user/jinxian_2024/share/proj/copyright_and_licenses.csv ']'
[1,0]<stderr>:++++ export PROJ_NETWORK=ON
[1,0]<stderr>:++++ PROJ_NETWORK=ON
[1,0]<stderr>:++ __conda_hashr
[1,0]<stderr>:++ '[' -n '' ']'
[1,0]<stderr>:++ '[' -n '' ']'
[1,0]<stderr>:++ hash -r
[1,0]<stderr>:+ commit_id=None
[1,0]<stderr>:+ export PATH=/nfs_beijing/kubeflow-user/jinxian_2024/bin/:/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+ PATH=/nfs_beijing/kubeflow-user/jinxian_2024/bin/:/nfs_beijing/kubeflow-user/jinxian_2024/bin:/opt/conda/condabin:/usr/local/bin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
[1,0]<stderr>:+ export WANDB_DIR=/nfs_beijing_ai/jinxian/rama-scoring1.3.0/logs
[1,0]<stderr>:+ WANDB_DIR=/nfs_beijing_ai/jinxian/rama-scoring1.3.0/logs
[1,0]<stderr>:+ export WANDB_IGNORE_GIT=1
[1,0]<stderr>:+ WANDB_IGNORE_GIT=1
[1,0]<stderr>:+ wandb_key=b00f1fee3fce213cd72cfeb42122329d758bf176
[1,0]<stderr>:+ wandb_name=NB_EquiformerV2_train
[1,0]<stderr>:+ wandb login --relogin b00f1fee3fce213cd72cfeb42122329d758bf176
[1,0]<stderr>:wandb: Appending key for api.wandb.ai to your netrc file: /nfs_beijing/kubeflow-user/jinjia2024/.netrc
[1,0]<stderr>:+++ dirname ./run_train_sin_k8s_trial6.sh
[1,0]<stderr>:++ cd .
[1,0]<stderr>:++ pwd
[1,0]<stderr>:+ PROJECT_DIR=/nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../../
[1,0]<stderr>:+ experiment_name=run_train_sin_k8s_trial6
[1,0]<stderr>:+ yaml_path=/nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../..//yamls/refine_train_yamls/run_train_sin_k8s_trial11.yaml
[1,0]<stderr>:+ device_ids=0
[1,0]<stderr>:+ gpus=1
[1,0]<stderr>:+ epochs=100
[1,0]<stderr>:+ max_epochs=100
[1,0]<stderr>:+ log_interval=200
[1,0]<stderr>:+ eval_interval=2000
[1,0]<stderr>:+ test_eval_interval=2000
[1,0]<stderr>:+ save_interval=2000
[1,0]<stderr>:+ start_decay_after_n_steps=50000
[1,0]<stderr>:+ decay_every_n_steps=50000
[1,0]<stderr>:+ warmup_no_steps=20000
[1,0]<stderr>:+ base_lr=0
[1,0]<stderr>:+ gradient_accumulation_steps=2
[1,0]<stderr>:+ override_some_deepspeed_config=gradient_accumulation_steps
[1,0]<stderr>:+ max_lr=0.0001
[1,0]<stderr>:+ output_dir=/nfs_beijing_ai/jinxian/rama-scoring1.3.0/trial6/
[1,0]<stderr>:+ launch_mode=k8s
[1,0]<stderr>:+ [[ xk8s == xlocal ]]
[1,0]<stderr>:++ nvidia-smi --query-gpu=name --format=csv,noheader
[1,0]<stderr>:++ wc -l
[1,0]<stderr>:+ gpu_count=4
[1,0]<stdout>:detect visiable gpus: 4
[1,0]<stderr>:+ echo 'detect visiable gpus: 4'
[1,0]<stderr>:+ torchrun --nproc_per_node=4 /nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../..//run_train_sin.py --deepspeed-init-dist --deepspeed_config /nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../..//deepspeed_config.json --yaml-path /nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../..//yamls/refine_train_yamls/run_train_sin_k8s_trial11.yaml --epochs 100 --log_interval 200 --eval_interval 2000 --save_interval 2000 --strict_eval --save /nfs_beijing_ai/jinxian/rama-scoring1.3.0/trial6/ --commit-id None --wandb --wandb-key b00f1fee3fce213cd72cfeb42122329d758bf176 --wandb-name NB_EquiformerV2_train --experiment-name run_train_sin_k8s_trial6 --max_epochs 100 --start_decay_after_n_steps 50000 --decay_every_n_steps 50000 --test_eval_interval 2000 --warmup_no_steps 20000 --base_lr 0 --max_lr 0.0001 --override_some_deepspeed_config gradient_accumulation_steps --gradient_accumulation_steps 2 --version 2
[1,0]<stderr>:WARNING:torch.distributed.run:
[1,0]<stderr>:*****************************************
[1,0]<stderr>:Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[1,0]<stderr>:*****************************************
[1,0]<stdout>:[2025-01-14 04:11:06,794] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[1,0]<stdout>:[2025-01-14 04:11:06,795] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[1,0]<stdout>:[2025-01-14 04:11:06,796] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[1,0]<stdout>:[2025-01-14 04:11:06,798] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[1,0]<stdout>:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[1,0]<stdout>:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[1,0]<stdout>:[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[1,0]<stdout>:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[1,0]<stdout>:[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[1,0]<stdout>:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[1,0]<stdout>:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[1,0]<stdout>:[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[1,0]<stdout>:
[1,0]<stdout>:[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[1,0]<stdout>:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[1,0]<stdout>:[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[1,0]<stdout>:[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[1,0]<stderr>:2025-01-14 04:11:45,112 INFO 43 [arguments.py:586] using world size: 4 and model-parallel size: 1 
[1,0]<stderr>:2025-01-14 04:11:45,112 INFO 43 [arguments.py:591] torch.distributed initialized? =False
[1,0]<stdout>:[2025-01-14 04:11:45,113] [INFO] [comm.py:637:init_distributed] cdb=None
[1,0]<stdout>:[2025-01-14 04:11:45,113] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[1,0]<stderr>:2025-01-14 04:11:45,114 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,114 INFO 46 [arguments.py:591] torch.distributed initialized? =False
[1,0]<stdout>:[2025-01-14 04:11:45,114] [INFO] [comm.py:637:init_distributed] cdb=None
[1,0]<stderr>:2025-01-14 04:11:45,114 INFO 45 [arguments.py:591] torch.distributed initialized? =False
[1,0]<stdout>:[2025-01-14 04:11:45,114] [INFO] [comm.py:637:init_distributed] cdb=None
[1,0]<stderr>:2025-01-14 04:11:45,115 INFO 44 [arguments.py:591] torch.distributed initialized? =False
[1,0]<stdout>:[2025-01-14 04:11:45,115] [INFO] [comm.py:637:init_distributed] cdb=None
[1,0]<stderr>:2025-01-14 04:11:45,115 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,115 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,115 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,116 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,116 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:2 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,124 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,124 INFO 43 [mpu_utils.py:62] > initializing model parallel with size 1
[1,0]<stderr>:2025-01-14 04:11:45,124 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:2 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,125 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,125 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:2 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:2 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:3 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,126 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:3 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,134 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,135 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:3 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:3 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:4 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:4 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,136 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:4 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,145 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,145 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:4 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,145 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,145 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:5 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,146 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:4 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,146 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:4 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,146 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:5 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,147 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:5 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,147 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:4 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,147 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:5 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,147 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:5 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,147 INFO 44 [distributed_c10d.py:319] Added key: store_based_barrier_key:6 to store for rank: 1
[1,0]<stderr>:2025-01-14 04:11:45,156 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,156 INFO 43 [distributed_c10d.py:319] Added key: store_based_barrier_key:6 to store for rank: 0
[1,0]<stderr>:2025-01-14 04:11:45,156 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:5 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:5 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 46 [distributed_c10d.py:319] Added key: store_based_barrier_key:6 to store for rank: 3
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 45 [distributed_c10d.py:319] Added key: store_based_barrier_key:6 to store for rank: 2
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 46 [distributed_c10d.py:353] Rank 3: Completed store-based barrier for key:store_based_barrier_key:6 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 45 [distributed_c10d.py:353] Rank 2: Completed store-based barrier for key:store_based_barrier_key:6 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 46 [arguments.py:639] nb-refinement-0-px5ws-worker-0-DP3/4-MP0/1-{'backend':'nccl','world_size':4,'rank':3,'local_rank':3,'init_method':'deepspeed_init_dist','device':3,'cuda':True,'device_num':4}
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 45 [arguments.py:639] nb-refinement-0-px5ws-worker-0-DP2/4-MP0/1-{'backend':'nccl','world_size':4,'rank':2,'local_rank':2,'init_method':'deepspeed_init_dist','device':2,'cuda':True,'device_num':4}
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 44 [distributed_c10d.py:353] Rank 1: Completed store-based barrier for key:store_based_barrier_key:6 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,157 INFO 44 [arguments.py:639] nb-refinement-0-px5ws-worker-0-DP1/4-MP0/1-{'backend':'nccl','world_size':4,'rank':1,'local_rank':1,'init_method':'deepspeed_init_dist','device':1,'cuda':True,'device_num':4}
[1,0]<stderr>:2025-01-14 04:11:45,166 INFO 43 [distributed_c10d.py:353] Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 4 nodes.
[1,0]<stderr>:2025-01-14 04:11:45,166 INFO 43 [arguments.py:639] nb-refinement-0-px5ws-worker-0-DP0/4-MP0/1-{'backend':'nccl','world_size':4,'rank':0,'local_rank':0,'init_method':'deepspeed_init_dist','device':0,'cuda':True,'device_num':4}
[1,0]<stderr>:2025-01-14 04:11:45,236 INFO 46 [run_train_sin.py:44] config_data:
[1,0]<stderr>:  ca_only: true
[1,0]<stderr>:  cdr3_col: CDR3_RMSD_CA
[1,0]<stderr>:  cdr3_threshold: 0.05
[1,0]<stderr>:  chain_col: chain
[1,0]<stderr>:  dataset_type: NB
[1,0]<stderr>:  debug: false
[1,0]<stderr>:  fast_warm_up_set:
[1,0]<stderr>:    size_ratio: 0.05
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  label_col: RMSD_CA
[1,0]<stderr>:  min_num_workers: 4
[1,0]<stderr>:  num_workers: 4
[1,0]<stderr>:  pdb_fpath_col: pred_path
[1,0]<stderr>:  prefetch_factor: 1
[1,0]<stderr>:  rmsd_scale:
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  sample_num: -1
[1,0]<stderr>:  screener:
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: RMSD_CA
[1,0]<stderr>:    upperbound: 5
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: CDR3_RMSD_CA
[1,0]<stderr>:    upperbound: 10
[1,0]<stderr>:  self_analyze:
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.5
[1,0]<stderr>:    - 0.8
[1,0]<stderr>:    - 1.1
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.7
[1,0]<stderr>:    - 2.0
[1,0]<stderr>:    - 2.4
[1,0]<stderr>:    - 2.8
[1,0]<stderr>:    - 3.2
[1,0]<stderr>:    - 3.6
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 200000
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.6
[1,0]<stderr>:    - 1.0
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.8
[1,0]<stderr>:    - 2.2
[1,0]<stderr>:    - 2.6
[1,0]<stderr>:    - 3.0
[1,0]<stderr>:    - 3.5
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 4.5
[1,0]<stderr>:    - 5.0
[1,0]<stderr>:    - 5.5
[1,0]<stderr>:    - 6.0
[1,0]<stderr>:    - 7.0
[1,0]<stderr>:    - 8.0
[1,0]<stderr>:    - 100000
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  test_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/model_zoo_nb_no4_95_testset_0522.csv
[1,0]<stderr>:  train_filepath:
[1,0]<stderr>:  - loss_weight: 1
[1,0]<stderr>:    name: esmflow_modeller_openmm_torchMD
[1,0]<stderr>:    path: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_train_all_decoys.csv
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  trn_batch_size: 8
[1,0]<stderr>:  val_batch_size: 1
[1,0]<stderr>:  valid_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_validation_one_decoys_each_model.csv
[1,0]<stderr>:  valid_head: 100
[1,0]<stderr>:config_model:
[1,0]<stderr>:  alpha_drop: 0.1
[1,0]<stderr>:  attn_activation: silu
[1,0]<stderr>:  attn_alpha_channels: 32
[1,0]<stderr>:  attn_hidden_channels: 64
[1,0]<stderr>:  attn_value_channels: 8
[1,0]<stderr>:  distance_function: gaussian
[1,0]<stderr>:  drop_path_rate: 0.05
[1,0]<stderr>:  edge_channels: 32
[1,0]<stderr>:  ffn_activation: silu
[1,0]<stderr>:  ffn_hidden_channels: 64
[1,0]<stderr>:  grid_resolution: 14
[1,0]<stderr>:  lmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  max_neighbors: 40
[1,0]<stderr>:  max_num_atom_names: 37
[1,0]<stderr>:  max_num_elements: 90
[1,0]<stderr>:  max_num_residues: 21
[1,0]<stderr>:  max_radius: 12.0
[1,0]<stderr>:  mmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  model_name: equiformer_v2
[1,0]<stderr>:  model_reload_path: false
[1,0]<stderr>:  norm_type: layer_norm_sh
[1,0]<stderr>:  num_distance_basis: 512
[1,0]<stderr>:  num_heads: 2
[1,0]<stderr>:  num_layers: 2
[1,0]<stderr>:  num_sphere_samples: 32
[1,0]<stderr>:  otf_graph: true
[1,0]<stderr>:  proj_drop: 0.0
[1,0]<stderr>:  regress_forces: true
[1,0]<stderr>:  share_atom_edge_embedding: false
[1,0]<stderr>:  sphere_channels: 24
[1,0]<stderr>:  use_atom_edge_embedding: true
[1,0]<stderr>:  use_attn_renorm: true
[1,0]<stderr>:  use_equivariant_block: true
[1,0]<stderr>:  use_gate_act: false
[1,0]<stderr>:  use_grid_mlp: true
[1,0]<stderr>:  use_invariant_block: false
[1,0]<stderr>:  use_pbc: false
[1,0]<stderr>:  use_s2_act_attn: false
[1,0]<stderr>:  use_sep_s2_act: true
[1,0]<stderr>:  weight_init: uniform
[1,0]<stderr>:config_runtime:
[1,0]<stderr>:  acc_grad: 1
[1,0]<stderr>:  angle_loss_mean_or_sum: mean
[1,0]<stderr>:  cdr1_loss_weight: 5
[1,0]<stderr>:  cdr2_loss_weight: 5
[1,0]<stderr>:  cdr3_loss_weight: 10
[1,0]<stderr>:  cg_loss_weight: 10
[1,0]<stderr>:  clip: 0.0
[1,0]<stderr>:  device: cuda
[1,0]<stderr>:  distmap_loss_mean_or_sum: mean
[1,0]<stderr>:  ema_decay: 0.9999
[1,0]<stderr>:  ema_start_epoch: 10
[1,0]<stderr>:  epoch: 100
[1,0]<stderr>:  learning_rate: 0.001
[1,0]<stderr>:  log_interval: 500
[1,0]<stderr>:  log_interval_for_test: 4000
[1,0]<stderr>:  loss_fn:
[1,0]<stderr>:  - output: 0
[1,0]<stderr>:    start_iter: 0
[1,0]<stderr>:    target: CDR3_RMSD_CA_scale
[1,0]<stderr>:    type: magnitude_loss
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  no_cdr_loss_weight: 1
[1,0]<stderr>:  num_epochs: 100000000
[1,0]<stderr>:  optimizer: adam
[1,0]<stderr>:  resume_from_ckpt: false
[1,0]<stderr>:  seed: 13
[1,0]<stderr>:  tran_loss_mean_or_sum: mean
[1,0]<stderr>:  tran_mse_loss_mean_or_sum: mean
[1,0]<stderr>:  use_CDR_loss: false
[1,0]<stderr>:  use_cg_loss: false
[1,0]<stderr>:  use_fsdp: false
[1,0]<stderr>:  use_tran_mse_loss: true
[1,0]<stderr>:  wd: 1.0e-08
[1,0]<stderr>:  weight_angle: 1
[1,0]<stderr>:  weight_angle_decay_rate: 0.99
[1,0]<stderr>:  weight_tran: 1
[1,0]<stderr>:
[1,0]<stdout>:ready to training!!!!!!!!
[1,0]<stderr>:2025-01-14 04:11:45,238 INFO 45 [run_train_sin.py:44] config_data:
[1,0]<stderr>:  ca_only: true
[1,0]<stderr>:  cdr3_col: CDR3_RMSD_CA
[1,0]<stderr>:  cdr3_threshold: 0.05
[1,0]<stderr>:  chain_col: chain
[1,0]<stderr>:  dataset_type: NB
[1,0]<stderr>:  debug: false
[1,0]<stderr>:  fast_warm_up_set:
[1,0]<stderr>:    size_ratio: 0.05
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  label_col: RMSD_CA
[1,0]<stderr>:  min_num_workers: 4
[1,0]<stderr>:  num_workers: 4
[1,0]<stderr>:  pdb_fpath_col: pred_path
[1,0]<stderr>:  prefetch_factor: 1
[1,0]<stderr>:  rmsd_scale:
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  sample_num: -1
[1,0]<stderr>:  screener:
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: RMSD_CA
[1,0]<stderr>:    upperbound: 5
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: CDR3_RMSD_CA
[1,0]<stderr>:    upperbound: 10
[1,0]<stderr>:  self_analyze:
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.5
[1,0]<stderr>:    - 0.8
[1,0]<stderr>:    - 1.1
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.7
[1,0]<stderr>:    - 2.0
[1,0]<stderr>:    - 2.4
[1,0]<stderr>:    - 2.8
[1,0]<stderr>:    - 3.2
[1,0]<stderr>:    - 3.6
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 200000
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.6
[1,0]<stderr>:    - 1.0
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.8
[1,0]<stderr>:    - 2.2
[1,0]<stderr>:    - 2.6
[1,0]<stderr>:    - 3.0
[1,0]<stderr>:    - 3.5
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 4.5
[1,0]<stderr>:    - 5.0
[1,0]<stderr>:    - 5.5
[1,0]<stderr>:    - 6.0
[1,0]<stderr>:    - 7.0
[1,0]<stderr>:    - 8.0
[1,0]<stderr>:    - 100000
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  test_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/model_zoo_nb_no4_95_testset_0522.csv
[1,0]<stderr>:  train_filepath:
[1,0]<stderr>:  - loss_weight: 1
[1,0]<stderr>:    name: esmflow_modeller_openmm_torchMD
[1,0]<stderr>:    path: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_train_all_decoys.csv
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  trn_batch_size: 8
[1,0]<stderr>:  val_batch_size: 1
[1,0]<stderr>:  valid_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_validation_one_decoys_each_model.csv
[1,0]<stderr>:  valid_head: 100
[1,0]<stderr>:config_model:
[1,0]<stderr>:  alpha_drop: 0.1
[1,0]<stderr>:  attn_activation: silu
[1,0]<stderr>:  attn_alpha_channels: 32
[1,0]<stderr>:  attn_hidden_channels: 64
[1,0]<stderr>:  attn_value_channels: 8
[1,0]<stderr>:  distance_function: gaussian
[1,0]<stderr>:  drop_path_rate: 0.05
[1,0]<stderr>:  edge_channels: 32
[1,0]<stderr>:  ffn_activation: silu
[1,0]<stderr>:  ffn_hidden_channels: 64
[1,0]<stderr>:  grid_resolution: 14
[1,0]<stderr>:  lmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  max_neighbors: 40
[1,0]<stderr>:  max_num_atom_names: 37
[1,0]<stderr>:  max_num_elements: 90
[1,0]<stderr>:  max_num_residues: 21
[1,0]<stderr>:  max_radius: 12.0
[1,0]<stderr>:  mmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  model_name: equiformer_v2
[1,0]<stderr>:  model_reload_path: false
[1,0]<stderr>:  norm_type: layer_norm_sh
[1,0]<stderr>:  num_distance_basis: 512
[1,0]<stderr>:  num_heads: 2
[1,0]<stderr>:  num_layers: 2
[1,0]<stderr>:  num_sphere_samples: 32
[1,0]<stderr>:  otf_graph: true
[1,0]<stderr>:  proj_drop: 0.0
[1,0]<stderr>:  regress_forces: true
[1,0]<stderr>:  share_atom_edge_embedding: false
[1,0]<stderr>:  sphere_channels: 24
[1,0]<stderr>:  use_atom_edge_embedding: true
[1,0]<stderr>:  use_attn_renorm: true
[1,0]<stderr>:  use_equivariant_block: true
[1,0]<stderr>:  use_gate_act: false
[1,0]<stderr>:  use_grid_mlp: true
[1,0]<stderr>:  use_invariant_block: false
[1,0]<stderr>:  use_pbc: false
[1,0]<stderr>:  use_s2_act_attn: false
[1,0]<stderr>:  use_sep_s2_act: true
[1,0]<stderr>:  weight_init: uniform
[1,0]<stderr>:config_runtime:
[1,0]<stderr>:  acc_grad: 1
[1,0]<stderr>:  angle_loss_mean_or_sum: mean
[1,0]<stderr>:  cdr1_loss_weight: 5
[1,0]<stderr>:  cdr2_loss_weight: 5
[1,0]<stderr>:  cdr3_loss_weight: 10
[1,0]<stderr>:  cg_loss_weight: 10
[1,0]<stderr>:  clip: 0.0
[1,0]<stderr>:  device: cuda
[1,0]<stderr>:  distmap_loss_mean_or_sum: mean
[1,0]<stderr>:  ema_decay: 0.9999
[1,0]<stderr>:  ema_start_epoch: 10
[1,0]<stderr>:  epoch: 100
[1,0]<stderr>:  learning_rate: 0.001
[1,0]<stderr>:  log_interval: 500
[1,0]<stderr>:  log_interval_for_test: 4000
[1,0]<stderr>:  loss_fn:
[1,0]<stderr>:  - output: 0
[1,0]<stderr>:    start_iter: 0
[1,0]<stderr>:    target: CDR3_RMSD_CA_scale
[1,0]<stderr>:    type: magnitude_loss
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  no_cdr_loss_weight: 1
[1,0]<stderr>:  num_epochs: 100000000
[1,0]<stderr>:  optimizer: adam
[1,0]<stderr>:  resume_from_ckpt: false
[1,0]<stderr>:  seed: 13
[1,0]<stderr>:  tran_loss_mean_or_sum: mean
[1,0]<stderr>:  tran_mse_loss_mean_or_sum: mean
[1,0]<stderr>:  use_CDR_loss: false
[1,0]<stderr>:  use_cg_loss: false
[1,0]<stderr>:  use_fsdp: false
[1,0]<stderr>:  use_tran_mse_loss: true
[1,0]<stderr>:  wd: 1.0e-08
[1,0]<stderr>:  weight_angle: 1
[1,0]<stderr>:  weight_angle_decay_rate: 0.99
[1,0]<stderr>:  weight_tran: 1
[1,0]<stderr>:
[1,0]<stdout>:ready to training!!!!!!!!
[1,0]<stderr>:2025-01-14 04:11:45,238 INFO 44 [run_train_sin.py:44] config_data:
[1,0]<stderr>:  ca_only: true
[1,0]<stderr>:  cdr3_col: CDR3_RMSD_CA
[1,0]<stderr>:  cdr3_threshold: 0.05
[1,0]<stderr>:  chain_col: chain
[1,0]<stderr>:  dataset_type: NB
[1,0]<stderr>:  debug: false
[1,0]<stderr>:  fast_warm_up_set:
[1,0]<stderr>:    size_ratio: 0.05
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  label_col: RMSD_CA
[1,0]<stderr>:  min_num_workers: 4
[1,0]<stderr>:  num_workers: 4
[1,0]<stderr>:  pdb_fpath_col: pred_path
[1,0]<stderr>:  prefetch_factor: 1
[1,0]<stderr>:  rmsd_scale:
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  sample_num: -1
[1,0]<stderr>:  screener:
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: RMSD_CA
[1,0]<stderr>:    upperbound: 5
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: CDR3_RMSD_CA
[1,0]<stderr>:    upperbound: 10
[1,0]<stderr>:  self_analyze:
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.5
[1,0]<stderr>:    - 0.8
[1,0]<stderr>:    - 1.1
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.7
[1,0]<stderr>:    - 2.0
[1,0]<stderr>:    - 2.4
[1,0]<stderr>:    - 2.8
[1,0]<stderr>:    - 3.2
[1,0]<stderr>:    - 3.6
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 200000
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.6
[1,0]<stderr>:    - 1.0
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.8
[1,0]<stderr>:    - 2.2
[1,0]<stderr>:    - 2.6
[1,0]<stderr>:    - 3.0
[1,0]<stderr>:    - 3.5
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 4.5
[1,0]<stderr>:    - 5.0
[1,0]<stderr>:    - 5.5
[1,0]<stderr>:    - 6.0
[1,0]<stderr>:    - 7.0
[1,0]<stderr>:    - 8.0
[1,0]<stderr>:    - 100000
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  test_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/model_zoo_nb_no4_95_testset_0522.csv
[1,0]<stderr>:  train_filepath:
[1,0]<stderr>:  - loss_weight: 1
[1,0]<stderr>:    name: esmflow_modeller_openmm_torchMD
[1,0]<stderr>:    path: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_train_all_decoys.csv
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  trn_batch_size: 8
[1,0]<stderr>:  val_batch_size: 1
[1,0]<stderr>:  valid_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_validation_one_decoys_each_model.csv
[1,0]<stderr>:  valid_head: 100
[1,0]<stderr>:config_model:
[1,0]<stderr>:  alpha_drop: 0.1
[1,0]<stderr>:  attn_activation: silu
[1,0]<stderr>:  attn_alpha_channels: 32
[1,0]<stderr>:  attn_hidden_channels: 64
[1,0]<stderr>:  attn_value_channels: 8
[1,0]<stderr>:  distance_function: gaussian
[1,0]<stderr>:  drop_path_rate: 0.05
[1,0]<stderr>:  edge_channels: 32
[1,0]<stderr>:  ffn_activation: silu
[1,0]<stderr>:  ffn_hidden_channels: 64
[1,0]<stderr>:  grid_resolution: 14
[1,0]<stderr>:  lmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  max_neighbors: 40
[1,0]<stderr>:  max_num_atom_names: 37
[1,0]<stderr>:  max_num_elements: 90
[1,0]<stderr>:  max_num_residues: 21
[1,0]<stderr>:  max_radius: 12.0
[1,0]<stderr>:  mmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  model_name: equiformer_v2
[1,0]<stderr>:  model_reload_path: false
[1,0]<stderr>:  norm_type: layer_norm_sh
[1,0]<stderr>:  num_distance_basis: 512
[1,0]<stderr>:  num_heads: 2
[1,0]<stderr>:  num_layers: 2
[1,0]<stderr>:  num_sphere_samples: 32
[1,0]<stderr>:  otf_graph: true
[1,0]<stderr>:  proj_drop: 0.0
[1,0]<stderr>:  regress_forces: true
[1,0]<stderr>:  share_atom_edge_embedding: false
[1,0]<stderr>:  sphere_channels: 24
[1,0]<stderr>:  use_atom_edge_embedding: true
[1,0]<stderr>:  use_attn_renorm: true
[1,0]<stderr>:  use_equivariant_block: true
[1,0]<stderr>:  use_gate_act: false
[1,0]<stderr>:  use_grid_mlp: true
[1,0]<stderr>:  use_invariant_block: false
[1,0]<stderr>:  use_pbc: false
[1,0]<stderr>:  use_s2_act_attn: false
[1,0]<stderr>:  use_sep_s2_act: true
[1,0]<stderr>:  weight_init: uniform
[1,0]<stderr>:config_runtime:
[1,0]<stderr>:  acc_grad: 1
[1,0]<stderr>:  angle_loss_mean_or_sum: mean
[1,0]<stderr>:  cdr1_loss_weight: 5
[1,0]<stderr>:  cdr2_loss_weight: 5
[1,0]<stderr>:  cdr3_loss_weight: 10
[1,0]<stderr>:  cg_loss_weight: 10
[1,0]<stderr>:  clip: 0.0
[1,0]<stderr>:  device: cuda
[1,0]<stderr>:  distmap_loss_mean_or_sum: mean
[1,0]<stderr>:  ema_decay: 0.9999
[1,0]<stderr>:  ema_start_epoch: 10
[1,0]<stderr>:  epoch: 100
[1,0]<stderr>:  learning_rate: 0.001
[1,0]<stderr>:  log_interval: 500
[1,0]<stderr>:  log_interval_for_test: 4000
[1,0]<stderr>:  loss_fn:
[1,0]<stderr>:  - output: 0
[1,0]<stderr>:    start_iter: 0
[1,0]<stderr>:    target: CDR3_RMSD_CA_scale
[1,0]<stderr>:    type: magnitude_loss
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  no_cdr_loss_weight: 1
[1,0]<stderr>:  num_epochs: 100000000
[1,0]<stderr>:  optimizer: adam
[1,0]<stderr>:  resume_from_ckpt: false
[1,0]<stderr>:  seed: 13
[1,0]<stderr>:  tran_loss_mean_or_sum: mean
[1,0]<stderr>:  tran_mse_loss_mean_or_sum: mean
[1,0]<stderr>:  use_CDR_loss: false
[1,0]<stderr>:  use_cg_loss: false
[1,0]<stderr>:  use_fsdp: false
[1,0]<stderr>:  use_tran_mse_loss: true
[1,0]<stderr>:  wd: 1.0e-08
[1,0]<stderr>:  weight_angle: 1
[1,0]<stderr>:  weight_angle_decay_rate: 0.99
[1,0]<stderr>:  weight_tran: 1
[1,0]<stderr>:
[1,0]<stdout>:ready to training!!!!!!!!
[1,0]<stderr>:2025-01-14 04:11:45,262 INFO 43 [run_train_sin.py:44] config_data:
[1,0]<stderr>:  ca_only: true
[1,0]<stderr>:  cdr3_col: CDR3_RMSD_CA
[1,0]<stderr>:  cdr3_threshold: 0.05
[1,0]<stderr>:  chain_col: chain
[1,0]<stderr>:  dataset_type: NB
[1,0]<stderr>:  debug: false
[1,0]<stderr>:  fast_warm_up_set:
[1,0]<stderr>:    size_ratio: 0.05
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  label_col: RMSD_CA
[1,0]<stderr>:  min_num_workers: 4
[1,0]<stderr>:  num_workers: 4
[1,0]<stderr>:  pdb_fpath_col: pred_path
[1,0]<stderr>:  prefetch_factor: 1
[1,0]<stderr>:  rmsd_scale:
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - scale_order: 1
[1,0]<stderr>:    scale_temp: 0.5
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  sample_num: -1
[1,0]<stderr>:  screener:
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: RMSD_CA
[1,0]<stderr>:    upperbound: 5
[1,0]<stderr>:  - class: UpperboundScreener
[1,0]<stderr>:    name: CDR3_RMSD_CA
[1,0]<stderr>:    upperbound: 10
[1,0]<stderr>:  self_analyze:
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.5
[1,0]<stderr>:    - 0.8
[1,0]<stderr>:    - 1.1
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.7
[1,0]<stderr>:    - 2.0
[1,0]<stderr>:    - 2.4
[1,0]<stderr>:    - 2.8
[1,0]<stderr>:    - 3.2
[1,0]<stderr>:    - 3.6
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 200000
[1,0]<stderr>:    target: RMSD_CA
[1,0]<stderr>:  - bin:
[1,0]<stderr>:    - 0
[1,0]<stderr>:    - 0.6
[1,0]<stderr>:    - 1.0
[1,0]<stderr>:    - 1.4
[1,0]<stderr>:    - 1.8
[1,0]<stderr>:    - 2.2
[1,0]<stderr>:    - 2.6
[1,0]<stderr>:    - 3.0
[1,0]<stderr>:    - 3.5
[1,0]<stderr>:    - 4.0
[1,0]<stderr>:    - 4.5
[1,0]<stderr>:    - 5.0
[1,0]<stderr>:    - 5.5
[1,0]<stderr>:    - 6.0
[1,0]<stderr>:    - 7.0
[1,0]<stderr>:    - 8.0
[1,0]<stderr>:    - 100000
[1,0]<stderr>:    target: CDR3_RMSD_CA
[1,0]<stderr>:  test_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/model_zoo_nb_no4_95_testset_0522.csv
[1,0]<stderr>:  train_filepath:
[1,0]<stderr>:  - loss_weight: 1
[1,0]<stderr>:    name: esmflow_modeller_openmm_torchMD
[1,0]<stderr>:    path: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_train_all_decoys.csv
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  trn_batch_size: 8
[1,0]<stderr>:  val_batch_size: 1
[1,0]<stderr>:  valid_filepath: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/dataset/datasets/NB_train_dataset_validation_one_decoys_each_model.csv
[1,0]<stderr>:  valid_head: 100
[1,0]<stderr>:config_model:
[1,0]<stderr>:  alpha_drop: 0.1
[1,0]<stderr>:  attn_activation: silu
[1,0]<stderr>:  attn_alpha_channels: 32
[1,0]<stderr>:  attn_hidden_channels: 64
[1,0]<stderr>:  attn_value_channels: 8
[1,0]<stderr>:  distance_function: gaussian
[1,0]<stderr>:  drop_path_rate: 0.05
[1,0]<stderr>:  edge_channels: 32
[1,0]<stderr>:  ffn_activation: silu
[1,0]<stderr>:  ffn_hidden_channels: 64
[1,0]<stderr>:  grid_resolution: 14
[1,0]<stderr>:  lmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  max_neighbors: 40
[1,0]<stderr>:  max_num_atom_names: 37
[1,0]<stderr>:  max_num_elements: 90
[1,0]<stderr>:  max_num_residues: 21
[1,0]<stderr>:  max_radius: 12.0
[1,0]<stderr>:  mmax_list:
[1,0]<stderr>:  - 2
[1,0]<stderr>:  model_name: equiformer_v2
[1,0]<stderr>:  model_reload_path: false
[1,0]<stderr>:  norm_type: layer_norm_sh
[1,0]<stderr>:  num_distance_basis: 512
[1,0]<stderr>:  num_heads: 2
[1,0]<stderr>:  num_layers: 2
[1,0]<stderr>:  num_sphere_samples: 32
[1,0]<stderr>:  otf_graph: true
[1,0]<stderr>:  proj_drop: 0.0
[1,0]<stderr>:  regress_forces: true
[1,0]<stderr>:  share_atom_edge_embedding: false
[1,0]<stderr>:  sphere_channels: 24
[1,0]<stderr>:  use_atom_edge_embedding: true
[1,0]<stderr>:  use_attn_renorm: true
[1,0]<stderr>:  use_equivariant_block: true
[1,0]<stderr>:  use_gate_act: false
[1,0]<stderr>:  use_grid_mlp: true
[1,0]<stderr>:  use_invariant_block: false
[1,0]<stderr>:  use_pbc: false
[1,0]<stderr>:  use_s2_act_attn: false
[1,0]<stderr>:  use_sep_s2_act: true
[1,0]<stderr>:  weight_init: uniform
[1,0]<stderr>:config_runtime:
[1,0]<stderr>:  acc_grad: 1
[1,0]<stderr>:  angle_loss_mean_or_sum: mean
[1,0]<stderr>:  cdr1_loss_weight: 5
[1,0]<stderr>:  cdr2_loss_weight: 5
[1,0]<stderr>:  cdr3_loss_weight: 10
[1,0]<stderr>:  cg_loss_weight: 10
[1,0]<stderr>:  clip: 0.0
[1,0]<stderr>:  device: cuda
[1,0]<stderr>:  distmap_loss_mean_or_sum: mean
[1,0]<stderr>:  ema_decay: 0.9999
[1,0]<stderr>:  ema_start_epoch: 10
[1,0]<stderr>:  epoch: 100
[1,0]<stderr>:  learning_rate: 0.001
[1,0]<stderr>:  log_interval: 500
[1,0]<stderr>:  log_interval_for_test: 4000
[1,0]<stderr>:  loss_fn:
[1,0]<stderr>:  - output: 0
[1,0]<stderr>:    start_iter: 0
[1,0]<stderr>:    target: CDR3_RMSD_CA_scale
[1,0]<stderr>:    type: magnitude_loss
[1,0]<stderr>:    weight: 1
[1,0]<stderr>:  no_cdr_loss_weight: 1
[1,0]<stderr>:  num_epochs: 100000000
[1,0]<stderr>:  optimizer: adam
[1,0]<stderr>:  resume_from_ckpt: false
[1,0]<stderr>:  seed: 13
[1,0]<stderr>:  tran_loss_mean_or_sum: mean
[1,0]<stderr>:  tran_mse_loss_mean_or_sum: mean
[1,0]<stderr>:  use_CDR_loss: false
[1,0]<stderr>:  use_cg_loss: false
[1,0]<stderr>:  use_fsdp: false
[1,0]<stderr>:  use_tran_mse_loss: true
[1,0]<stderr>:  wd: 1.0e-08
[1,0]<stderr>:  weight_angle: 1
[1,0]<stderr>:  weight_angle_decay_rate: 0.99
[1,0]<stderr>:  weight_tran: 1
[1,0]<stderr>:
[1,0]<stdout>:ready to training!!!!!!!!
[1,0]<stdout>:total_train_data: 1103021
[1,0]<stdout>:total_valid_data: 1023
[1,0]<stdout>:total_test_data: 968
[1,0]<stdout>:We will training on gpu: 0
[1,0]<stdout>:train_dataloader length: 34469[1,0]<stdout>:
[1,0]<stdout>:valid_dataloader length: 256
[1,0]<stdout>:test_dataloader length: 242
[1,0]<stdout>:total_train_data: 1103021
[1,0]<stdout>:total_valid_data: 1023
[1,0]<stdout>:total_test_data: 968
[1,0]<stdout>:We will training on gpu: 3
[1,0]<stdout>:train_dataloader length: 34469
[1,0]<stdout>:valid_dataloader length: 256
[1,0]<stdout>:test_dataloader length: 242
[1,0]<stdout>:total_train_data: 1103021
[1,0]<stdout>:total_valid_data: 1023
[1,0]<stdout>:total_test_data: 968
[1,0]<stdout>:We will training on gpu: 2
[1,0]<stdout>:train_dataloader length: 34469
[1,0]<stdout>:valid_dataloader length: 256
[1,0]<stdout>:test_dataloader length: 242
[1,0]<stdout>:total_train_data: 1103021
[1,0]<stdout>:total_valid_data: 1023
[1,0]<stdout>:total_test_data: 968
[1,0]<stdout>:We will training on gpu: 1
[1,0]<stdout>:train_dataloader length: 34469
[1,0]<stdout>:valid_dataloader length: 256
[1,0]<stdout>:test_dataloader length: 242
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:43 [0] NCCL INFO Bootstrap : Using eth0:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:43 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:43 [0] NCCL INFO cudaDriverVersion 12000
[1,0]<stdout>:NCCL version 2.14.3+cuda11.6
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:46 [3] NCCL INFO cudaDriverVersion 12000
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:46 [3] NCCL INFO Bootstrap : Using eth0:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO NET/IB : No device found.
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO NET/Socket : Using [0]eth0:172.22.65.51<0> [1]eth1:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Using network Socket
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:45 [2] NCCL INFO cudaDriverVersion 12000
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:45 [2] NCCL INFO Bootstrap : Using eth0:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:44 [1] NCCL INFO cudaDriverVersion 12000
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:44 [1] NCCL INFO Bootstrap : Using eth0:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:46 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO NET/IB : No device found.
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO NET/Socket : Using [0]eth0:172.22.65.51<0> [1]eth1:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Using network Socket
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:45 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:44 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO NET/IB : No device found.
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO NET/Socket : Using [0]eth0:172.22.65.51<0> [1]eth1:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Using network Socket
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO NET/IB : No device found.
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO NET/Socket : Using [0]eth0:172.22.65.51<0> [1]eth1:172.22.65.51<0>
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Using network Socket
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Setting affinity for GPU 0 to ffffffff,00000000,ffffffff
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Setting affinity for GPU 2 to ffffffff,00000000,ffffffff,00000000
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Setting affinity for GPU 1 to ffffffff,00000000,ffffffff
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Setting affinity for GPU 3 to ffffffff,00000000,ffffffff,00000000
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 00/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->2 [5] -1/-1/-1->3->2 [6] -1/-1/-1->3->2 [7] -1/-1/-1->3->2 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] -1/-1/-1->3->2 [11] -1/-1/-1->3->2 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 01/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 02/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 03/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 04/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 05/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 06/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 07/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 08/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 09/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 10/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 11/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 12/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 13/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 14/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 15/16 :    0   1   2   3
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 00/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 00/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 01/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 00/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 00/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 01/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 02/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 01/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 01/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 02/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 03/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 02/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 02/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 03/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 04/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 03/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 03/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 04/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 05/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 04/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 04/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 05/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 06/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 05/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 05/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 06/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 07/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 06/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 06/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 07/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 08/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 07/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 07/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 08/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 09/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 08/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 08/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 09/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 09/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 10/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 10/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 09/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 10/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 11/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 10/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 11/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 11/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 12/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 11/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 12/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 12/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 13/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 12/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 13/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 13/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 14/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 13/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 14/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 14/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 15/0 : 1[72000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 14/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Channel 15/0 : 0[6c000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 15/0 : 3[b1000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 15/0 : 2[ad000] -> 3[b1000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Connected all rings
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 00/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 01/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 02/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 03/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 04/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 05/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 06/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 07/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 08/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 09/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 10/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 11/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 12/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 13/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 14/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Channel 15/0 : 3[b1000] -> 2[ad000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Connected all rings
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Connected all rings
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Connected all rings
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 00/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 01/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 02/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 00/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 03/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 01/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 04/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 02/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 05/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 03/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 06/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 04/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 07/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 05/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 08/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 06/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 09/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 07/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 10/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 08/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 11/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 09/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 12/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 10/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 13/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 11/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 14/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 12/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Channel 15/0 : 1[72000] -> 0[6c000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 13/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 14/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Channel 15/0 : 2[ad000] -> 1[72000] via P2P/IPC/read
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO Connected all trees
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO 16 coll channels, 16 p2p channels, 16 p2p channels per peer
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO Connected all trees
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO 16 coll channels, 16 p2p channels, 16 p2p channels per peer
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO Connected all trees
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO 16 coll channels, 16 p2p channels, 16 p2p channels per peer
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO Connected all trees
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO 16 coll channels, 16 p2p channels, 16 p2p channels per peer
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:46:177 [3] NCCL INFO comm 0x55ad6e6c9840 rank 3 nranks 4 cudaDev 3 busId b1000 - Init COMPLETE
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:45:178 [2] NCCL INFO comm 0x557b03664180 rank 2 nranks 4 cudaDev 2 busId ad000 - Init COMPLETE
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:44:179 [1] NCCL INFO comm 0x555ec370fbc0 rank 1 nranks 4 cudaDev 1 busId 72000 - Init COMPLETE
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:176 [0] NCCL INFO comm 0x564ee497b880 rank 0 nranks 4 cudaDev 0 busId 6c000 - Init COMPLETE
[1,0]<stdout>:No checkpoint found. Training from scratch.No checkpoint found. Training from scratch.No checkpoint found. Training from scratch.No checkpoint found. Training from scratch.
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stderr>:wandb: Currently logged in as: wangjx22 (jinxianwang). Use `wandb login --relogin` to force relogin
[1,0]<stdout>:Problem at:[1,0]<stdout>: /nfs_beijing_ai/jinxian/rama-scoring1.3.0/utils/../dataset/sin_equiformerv2_dataset.py[1,0]<stdout>: 1503 test_run_train
[1,0]<stderr>:wandb: ERROR Error communicating with wandb process
[1,0]<stderr>:wandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))
[1,0]<stderr>:wandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))
[1,0]<stderr>:wandb: ERROR For more info see: https://docs.wandb.ai/library/init#init-start-error
[1,0]<stderr>:2025-01-14 04:13:10,719 INFO 43 [run_train_sin.py:64] Rank=0, caught unexpected error: Traceback (most recent call last):
[1,0]<stderr>:  File "/nfs_beijing_ai/jinxian/rama-scoring1.3.0/bin/sin_equiformerV2_train_shs/../..//run_train_sin.py", line 58, in main
[1,0]<stderr>:    test_run_train(args, yaml_args["config_runtime"], yaml_args["config_model"], yaml_args["config_data"])
[1,0]<stderr>:  File "/nfs_beijing_ai/jinxian/rama-scoring1.3.0/utils/../dataset/sin_equiformerv2_dataset.py", line 1503, in test_run_train
[1,0]<stderr>:    wandb_config = wandb.init(
[1,0]<stderr>:  File "/nfs_beijing/kubeflow-user/jinxian_2024/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 1043, in init
[1,0]<stderr>:    run = wi.init()
[1,0]<stderr>:  File "/nfs_beijing/kubeflow-user/jinxian_2024/lib/python3.8/site-packages/wandb/sdk/wandb_init.py", line 691, in init
[1,0]<stderr>:    raise UsageError(error_message)
[1,0]<stderr>:wandb.errors.UsageError: Error communicating with wandb process
[1,0]<stderr>:try: wandb.init(settings=wandb.Settings(start_method='fork'))
[1,0]<stderr>:or:  wandb.init(settings=wandb.Settings(start_method='thread'))
[1,0]<stderr>:For more info see: https://docs.wandb.ai/library/init#init-start-error
[1,0]<stderr>:
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:180 [0] NCCL INFO [Service thread] Connection closed by localRank 0
[1,0]<stdout>:nb-refinement-0-px5ws-worker-0:43:43 [0] NCCL INFO comm 0x564ee497b880 rank 0 nranks 4 cudaDev 0 busId 6c000 - Abort COMPLETE
